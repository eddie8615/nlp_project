{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "173dabd1",
   "metadata": {
    "id": "173dabd1"
   },
   "source": [
    "## NLP project\n",
    "\n",
    "Read all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "oXhnBi_na7XD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXhnBi_na7XD",
    "outputId": "b292ff7b-c30e-49ea-9e52-db9c1e68c6f1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# %cd /content/drive/My Drive/Colab Notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24ffb5e",
   "metadata": {
    "id": "d24ffb5e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351d2aeb",
   "metadata": {
    "id": "351d2aeb"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.txt', sep='\\t', header=None, names=['pmid', 'label', 'txt'])\n",
    "dev_data = pd.read_csv('dev.txt', sep='\\t', header=None, names=['pmid', 'label', 'txt'])\n",
    "test_data = pd.read_csv('test.txt', sep='\\t', header=None, names=['pmid', 'label', 'txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02f59a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "id": "c02f59a9",
    "outputId": "7977d4f3-393a-448b-cc05-6fed58419da5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2447c61f90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['label'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "027b2e38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "027b2e38",
    "outputId": "3f884ffa-0c5a-4234-a135-b1ce6109de5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Downloader\n",
      "---------------------------------------------------------------------------\n",
      "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
      "---------------------------------------------------------------------------\n",
      "Downloader> q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import ssl\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download()\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e038a07f",
   "metadata": {
    "id": "e038a07f"
   },
   "outputs": [],
   "source": [
    "# Cleaning process such that replacing punctuation to space, deleting them, or making them lowercase\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    punctuation = [i for i in ',./\\\\;:\\'@#~[{]}=+-_)(*&^%$£\"!`)]']\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    \n",
    "    text = text.replace(\"'s\", \"\")\n",
    "    text = \"\".join([\" \" if t in punctuation else t for t in text]).lower()\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwords from text\n",
    "    return text\n",
    "\n",
    "def split_training_set(X_train, y_train):\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "    for first_index, second_index in skf.split(X_train, y_train):\n",
    "        X_train_f, X_train_s = X_train[first_index], X_train[second_index]\n",
    "        y_train_f, y_train_s = y_train[first_index], y_train[second_index]\n",
    "        \n",
    "    return X_train_f, y_train_f, X_train_s, y_train_s\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    y_true = le.inverse_transform(y_true)\n",
    "    y_pred = le.inverse_transform(y_pred)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ad384a",
   "metadata": {
    "id": "f1ad384a"
   },
   "source": [
    "### Which vectorizer is the best? Tf-idf vs Bag of words\n",
    "This section aims to find out the best vectorizer that makes the first two machine learning models having better performance with respect to F1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c5f466c",
   "metadata": {
    "id": "1c5f466c"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a65fe6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5a65fe6",
    "outputId": "cf3a54da-6764-4258-ef36-590b9e7a4277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.1 s, sys: 2.64 s, total: 50.7 s\n",
      "Wall time: 54.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_text_cleaned = train_data['txt'].apply(clean_text)\n",
    "devel_text_cleaned = dev_data['txt'].apply(clean_text)\n",
    "test_text_cleaned = test_data['txt'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a664fd4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a664fd4d",
    "outputId": "f6883a48-786e-4a6f-caae-466ba2fa244c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.657292769365306,\n",
       " 1: 1.3253828032979977,\n",
       " 2: 0.6066753154853166,\n",
       " 3: 2.6019221041982803,\n",
       " 4: 0.6213310786326851}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_data['label'])\n",
    "y_devel = le.transform(dev_data['label'])\n",
    "y_test = le.transform(test_data['label'])\n",
    "\n",
    "cw = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "cw_dict = dict(zip(np.unique(y_train), cw))\n",
    "cw_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79def5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2d79def5",
    "outputId": "f15f1486-69ab-40db-e98e-dc63fb24e9e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Bag of word result----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BACKGROUND       0.52      0.58      0.55      3449\n",
      " CONCLUSIONS       0.65      0.68      0.67      4582\n",
      "     METHODS       0.86      0.85      0.85      9964\n",
      "   OBJECTIVE       0.50      0.55      0.53      2376\n",
      "     RESULTS       0.88      0.82      0.84      9841\n",
      "\n",
      "    accuracy                           0.76     30212\n",
      "   macro avg       0.68      0.69      0.69     30212\n",
      "weighted avg       0.77      0.76      0.76     30212\n",
      "\n",
      "-------TFIDF result----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BACKGROUND       0.55      0.60      0.57      3449\n",
      " CONCLUSIONS       0.65      0.71      0.68      4582\n",
      "     METHODS       0.87      0.85      0.86      9964\n",
      "   OBJECTIVE       0.51      0.61      0.56      2376\n",
      "     RESULTS       0.89      0.80      0.85      9841\n",
      "\n",
      "    accuracy                           0.77     30212\n",
      "   macro avg       0.70      0.72      0.70     30212\n",
      "weighted avg       0.78      0.77      0.77     30212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bow_vec = CountVectorizer(tokenizer=word_tokenize)\n",
    "tfidf = TfidfVectorizer(tokenizer=word_tokenize)\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "bow_pipeline = Pipeline([\n",
    "    ('bow', bow_vec),\n",
    "    ('LR', LogisticRegression(class_weight=cw_dict, random_state=random_seed, n_jobs=-1))\n",
    "])\n",
    "\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('LR', LogisticRegression(class_weight=cw_dict, random_state=random_seed, n_jobs=-1))\n",
    "])\n",
    "\n",
    "print('-------Bag of word result----------')\n",
    "bow_pipeline.fit(train_text_cleaned, y_train)\n",
    "y_pred = bow_pipeline.predict(devel_text_cleaned)\n",
    "evaluate(y_devel, y_pred)\n",
    "\n",
    "print('-------TFIDF result----------')\n",
    "tfidf_pipeline.fit(train_text_cleaned, y_train)\n",
    "y_pred = tfidf_pipeline.predict(devel_text_cleaned)\n",
    "evaluate(y_devel, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90530c",
   "metadata": {
    "id": "ca90530c"
   },
   "source": [
    "From the experiment, we noticed that TFIDF vectorizer is bit more effective to improve LR's performance.\n",
    "\n",
    "Next, we need to discover the sufficient ngram range for TF-IDF vectorizer to have the best performance. This stage also considers the computational time for each ngram size simultaneously. \n",
    "\n",
    "*Result*\n",
    "bigram and trigram show better performance than unigram. However, for trigram, it takes about 5minutes compared to 11 sec for unigram\n",
    "\n",
    "ngram_range=(1,2) is reasonable to get feasible running time and better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66041730",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66041730",
    "outputId": "905ac8a6-c726-43f6-c534-c0e32637a842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 21.688993215560913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BACKGROUND       0.55      0.58      0.57      3449\n",
      " CONCLUSIONS       0.66      0.71      0.68      4582\n",
      "     METHODS       0.87      0.85      0.86      9964\n",
      "   OBJECTIVE       0.51      0.61      0.56      2376\n",
      "     RESULTS       0.89      0.81      0.85      9841\n",
      "\n",
      "    accuracy                           0.77     30212\n",
      "   macro avg       0.69      0.71      0.70     30212\n",
      "weighted avg       0.78      0.77      0.77     30212\n",
      "\n",
      "Time elapsed: 137.30048251152039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BACKGROUND       0.60      0.60      0.60      3449\n",
      " CONCLUSIONS       0.67      0.75      0.71      4582\n",
      "     METHODS       0.87      0.87      0.87      9964\n",
      "   OBJECTIVE       0.56      0.60      0.58      2376\n",
      "     RESULTS       0.89      0.82      0.85      9841\n",
      "\n",
      "    accuracy                           0.78     30212\n",
      "   macro avg       0.72      0.73      0.72     30212\n",
      "weighted avg       0.79      0.78      0.79     30212\n",
      "\n",
      "Time elapsed: 320.9190831184387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BACKGROUND       0.62      0.57      0.59      3449\n",
      " CONCLUSIONS       0.66      0.75      0.70      4582\n",
      "     METHODS       0.86      0.87      0.86      9964\n",
      "   OBJECTIVE       0.55      0.65      0.60      2376\n",
      "     RESULTS       0.89      0.81      0.85      9841\n",
      "\n",
      "    accuracy                           0.78     30212\n",
      "   macro avg       0.72      0.73      0.72     30212\n",
      "weighted avg       0.79      0.78      0.78     30212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ngram_candidates = [(1,1), (1,2), (1,3)]\n",
    "\n",
    "for ngram in ngram_candidates:\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=ngram)),\n",
    "        ('LR', LogisticRegression(class_weight=cw_dict, random_state=random_seed, n_jobs=-1))\n",
    "    ])\n",
    "    tick = time.time()\n",
    "    pipeline.fit(train_text_cleaned, y_train)\n",
    "    tock = time.time()\n",
    "    print('Time elapsed:', tock-tick)\n",
    "    y_pred = pipeline.predict(devel_text_cleaned)\n",
    "    evaluate(y_devel, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59ffca6",
   "metadata": {},
   "source": [
    "### Model1: Logistic Regression with Tf-idf vectorizer \n",
    "\n",
    "The first model which is the baseline model is to use logistic regression. The only given hyperparameter is balancing class weights for handling imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4cb13c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc4cb13c",
    "outputId": "9278f2ee-fbd8-4071-e2dc-db4bb5697b27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(ngram_range=(1, 2),\n",
       "                                 tokenizer=<function word_tokenize at 0x7f1d65a39b00>)),\n",
       "                ('LR',\n",
       "                 LogisticRegression(class_weight={0: 1.657292769365306,\n",
       "                                                  1: 1.3253828032979977,\n",
       "                                                  2: 0.6066753154853166,\n",
       "                                                  3: 2.6019221041982803,\n",
       "                                                  4: 0.6213310786326851},\n",
       "                                    n_jobs=-1, random_state=42))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram = (1,2)\n",
    "\n",
    "model_1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer=word_tokenize, ngram_range=ngram)),\n",
    "    ('LR', LogisticRegression(class_weight=cw_dict, random_state=random_seed, n_jobs=-1))\n",
    "])\n",
    "model_1.fit(train_text_cleaned, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576a167",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8576a167",
    "outputId": "f7ff39ee-fd54-424e-9863-0bc489e2143a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BACKGROUND       0.59      0.60      0.59      3449\n",
      " CONCLUSIONS       0.65      0.75      0.70      4582\n",
      "     METHODS       0.86      0.87      0.87      9964\n",
      "   OBJECTIVE       0.55      0.64      0.59      2376\n",
      "     RESULTS       0.90      0.80      0.85      9841\n",
      "\n",
      "    accuracy                           0.78     30212\n",
      "   macro avg       0.71      0.73      0.72     30212\n",
      "weighted avg       0.79      0.78      0.78     30212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_1.predict(devel_text_cleaned)\n",
    "evaluate(y_devel, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4a4810",
   "metadata": {},
   "source": [
    "### Model2: Linear SVM with Tf-idf Vectorizer\n",
    "\n",
    "The next model is Linear SVM with the same technique for imbalanced data. Additional hyperparameter for SVM is cost parameter which is set to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afb415",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "79afb415",
    "outputId": "35a4f505-285a-467b-c4ff-f57fb037a120"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tf-idf',\n",
       "                 TfidfVectorizer(ngram_range=(1, 2),\n",
       "                                 tokenizer=<function word_tokenize at 0x7f1d65a39b00>)),\n",
       "                ('LinearSVM',\n",
       "                 LinearSVC(C=1,\n",
       "                           class_weight={0: 1.657292769365306,\n",
       "                                         1: 1.3253828032979977,\n",
       "                                         2: 0.6066753154853166,\n",
       "                                         3: 2.6019221041982803,\n",
       "                                         4: 0.6213310786326851},\n",
       "                           random_state=42))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = Pipeline([\n",
    "    (\"tf-idf\", TfidfVectorizer(tokenizer=word_tokenize, ngram_range=ngram)),\n",
    "    (\"LinearSVM\", LinearSVC(class_weight=cw_dict, random_state=random_seed, C=1))\n",
    "])\n",
    "model_2.fit(train_text_cleaned, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c0ac9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d9c0ac9",
    "outputId": "096d1a9d-986f-41a9-e047-79a3dbebf1fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BACKGROUND       0.61      0.58      0.60      3449\n",
      " CONCLUSIONS       0.70      0.73      0.71      4582\n",
      "     METHODS       0.85      0.91      0.88      9964\n",
      "   OBJECTIVE       0.61      0.57      0.59      2376\n",
      "     RESULTS       0.89      0.85      0.87      9841\n",
      "\n",
      "    accuracy                           0.80     30212\n",
      "   macro avg       0.73      0.73      0.73     30212\n",
      "weighted avg       0.80      0.80      0.80     30212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_2.predict(devel_text_cleaned)\n",
    "evaluate(y_devel, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2601c3b",
   "metadata": {},
   "source": [
    "### Model3: Conv1D network\n",
    "\n",
    "#### Word Embedding layer\n",
    "Prior to build word embedding layer, the texts were vectorized using `TextVectorization`. The vectors are encoded as 296 word sequence length which is the maximum length in the entire sentences in the training set. The max size of vocabulary of this vectorizer is 68,000 which is the total number of vocabulary in the training set. After vectorizing, embedding dimension is set to 150 as my machine can handle.\n",
    "#### Conv1D layer\n",
    "- filter_size = 64\n",
    "- kernel_size = 5\n",
    "- activation = ReLU\n",
    "- Dropout = 0.2\n",
    "\n",
    "#### Training setting\n",
    "- epochs = 3\n",
    "- batch_size = 256\n",
    "- balancing class weights\n",
    "\n",
    "Such setting follows the codes from practical session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bd0cfc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bd0cfc6",
    "outputId": "bd2b6552-e598-4eaa-80e2-8a52d078553e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "sentence_len = [len(sent.split()) for sent in train_data['txt'].tolist()]\n",
    "max(sentence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56df8096",
   "metadata": {
    "id": "56df8096"
   },
   "outputs": [],
   "source": [
    "max_tokens = 68000\n",
    "seq_len = 296\n",
    "\n",
    "text_vec = TextVectorization(max_tokens=max_tokens, \n",
    "                             pad_to_max_tokens=True, \n",
    "                             output_sequence_length=seq_len,\n",
    "                             output_mode='int')\n",
    "text_vec.adapt(train_text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9986a6f8",
   "metadata": {
    "id": "9986a6f8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical, set_random_seed\n",
    "\n",
    "random_seed = 42\n",
    "embedding_dim = 150\n",
    "hidden_dims=32\n",
    "filter1 = 64\n",
    "kernel_size=5\n",
    "input_dim = len(text_vec.get_vocabulary())\n",
    "set_random_seed(random_seed)\n",
    "# np.set_random_seed(random_seed)\n",
    "\n",
    "y_train_vec = to_categorical(y_train, num_classes=5, dtype=int)\n",
    "y_devel_vec = to_categorical(y_devel, num_classes=5, dtype=int)\n",
    "y_test_vec = to_categorical(y_test, num_classes=5, dtype=int)\n",
    "\n",
    "# x_train = pad_sequences(train_text_cleaned, maxlen=seq_len)\n",
    "# x_test = pad_sequences(devel_text_cleaned, maxlen=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17accdf0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17accdf0",
    "outputId": "4c236e64-bf9d-49b2-b581-b96c83ca035b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished building model.\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 296)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 296, 150)          8685300   \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 292, 64)           48064     \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,733,689\n",
      "Trainable params: 8,733,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, Dropout, Dropout, Dense, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "model.add(text_vec)\n",
    "model.add(Embedding(input_dim=input_dim,\n",
    "                    output_dim=embedding_dim,\n",
    "                    mask_zero=True,\n",
    "                   input_length=seq_len))\n",
    "model.add(Conv1D(filter1,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Finished building model.\\n')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08ee6dcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08ee6dcf",
    "outputId": "05f890b6-ca33-4b7c-b7aa-d0dc3ce47953"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5627/5627 [==============================] - 63s 11ms/step - loss: 0.8069 - accuracy: 0.7401 - val_loss: 0.6015 - val_accuracy: 0.7844\n",
      "Epoch 2/3\n",
      "5627/5627 [==============================] - 66s 12ms/step - loss: 0.5743 - accuracy: 0.8240 - val_loss: 0.6388 - val_accuracy: 0.7687\n",
      "Epoch 3/3\n",
      "5627/5627 [==============================] - 63s 11ms/step - loss: 0.3950 - accuracy: 0.8788 - val_loss: 0.6800 - val_accuracy: 0.7737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2259301b10>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_text_cleaned, y_train_vec, class_weight=cw_dict, batch_size=32, epochs=3, validation_data=(devel_text_cleaned, y_devel_vec))\n",
    "# y_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90fe9b29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90fe9b29",
    "outputId": "805395b0-b58f-4b39-fe03-6a640db503a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  BACKGROUND       0.55      0.59      0.57      3449\n",
      " CONCLUSIONS       0.66      0.71      0.69      4582\n",
      "     METHODS       0.87      0.86      0.87      9964\n",
      "   OBJECTIVE       0.56      0.58      0.57      2376\n",
      "     RESULTS       0.88      0.82      0.85      9841\n",
      "\n",
      "    accuracy                           0.77     30212\n",
      "   macro avg       0.70      0.71      0.71     30212\n",
      "weighted avg       0.78      0.77      0.78     30212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_vec = model.predict(devel_text_cleaned)\n",
    "y_pred = np.argmax(y_pred_vec, axis=1)\n",
    "evaluate(y_devel, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f608a4",
   "metadata": {
    "id": "7e6123a8"
   },
   "source": [
    "### Model4: Different embedding layer with the Conv1D network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013773f6",
   "metadata": {},
   "source": [
    "### Model5: Model from the paper\n",
    "\n",
    "According to the paper [(Neural Networks for Joint Sentence classification in Mecial Paper Abstracts)](https://arxiv.org/pdf/1612.05251.pdf), the suggested model outperforms other baseline models such as Logistic Regression, Forward ANN, and CRF. The last model follows the instructions at the paper.\n",
    "\n",
    "- Additional information for the model is to label which line is the corresponding sentence in the abstract and give the total number of lines in the abstract.\n",
    "This should be effective because abstracts are typically structured writing especially medical paper. Additionally, it is obvious the 'METHOD' part is followed by 'RESULT' part. Such information would be helpful for the model to classify the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "016707a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46577/1246308742.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['total_lines'][i-count:i] = count\n",
      "/tmp/ipykernel_46577/1246308742.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['total_lines'][i-count+1:] = count\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>label</th>\n",
       "      <th>txt</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24293578</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>To investigate the efficacy of 6 weeks of dail...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24293578</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>A total of 125 patients with primary knee OA w...</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24293578</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>Outcome measures included pain reduction and i...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24293578</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>Pain was assessed using the visual analog pain...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24293578</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>Secondary outcome measures included the Wester...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180035</th>\n",
       "      <td>26227186</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>For the absolute change in percent atheroma vo...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180036</th>\n",
       "      <td>26227186</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>For PAV , a significantly greater percentage o...</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180037</th>\n",
       "      <td>26227186</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Both strategies had acceptable side effect pro...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180038</th>\n",
       "      <td>26227186</td>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>Compared with standard statin monotherapy , th...</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180039</th>\n",
       "      <td>26227186</td>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>( Plaque Regression With Cholesterol Absorptio...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180040 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pmid        label  \\\n",
       "0       24293578    OBJECTIVE   \n",
       "1       24293578      METHODS   \n",
       "2       24293578      METHODS   \n",
       "3       24293578      METHODS   \n",
       "4       24293578      METHODS   \n",
       "...          ...          ...   \n",
       "180035  26227186      RESULTS   \n",
       "180036  26227186      RESULTS   \n",
       "180037  26227186      RESULTS   \n",
       "180038  26227186  CONCLUSIONS   \n",
       "180039  26227186  CONCLUSIONS   \n",
       "\n",
       "                                                      txt  line_number  \\\n",
       "0       To investigate the efficacy of 6 weeks of dail...            1   \n",
       "1       A total of 125 patients with primary knee OA w...            2   \n",
       "2       Outcome measures included pain reduction and i...            3   \n",
       "3       Pain was assessed using the visual analog pain...            4   \n",
       "4       Secondary outcome measures included the Wester...            5   \n",
       "...                                                   ...          ...   \n",
       "180035  For the absolute change in percent atheroma vo...            8   \n",
       "180036  For PAV , a significantly greater percentage o...            9   \n",
       "180037  Both strategies had acceptable side effect pro...           10   \n",
       "180038  Compared with standard statin monotherapy , th...           11   \n",
       "180039  ( Plaque Regression With Cholesterol Absorptio...           12   \n",
       "\n",
       "        total_lines  \n",
       "0                12  \n",
       "1                12  \n",
       "2                12  \n",
       "3                12  \n",
       "4                12  \n",
       "...             ...  \n",
       "180035           12  \n",
       "180036           12  \n",
       "180037           12  \n",
       "180038           12  \n",
       "180039           12  \n",
       "\n",
       "[180040 rows x 5 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = []\n",
    "current = 0\n",
    "count = 0\n",
    "train_data['total_lines'] = 0\n",
    "for i, id in enumerate(train_data['pmid']):\n",
    "    if current != id:\n",
    "        train_data['total_lines'][i-count:i] = count\n",
    "        current = id\n",
    "        count = 1\n",
    "    else:\n",
    "        count += 1\n",
    "    lines.append(count)\n",
    "\n",
    "train_data['total_lines'][i-count+1:] = count\n",
    "train_data['line_number'] = lines\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff1d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2a0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pubmed_nlp.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "nlp_proj",
   "language": "python",
   "name": "nlp_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
